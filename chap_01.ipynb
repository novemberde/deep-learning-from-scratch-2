{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 1. 신경망 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1. 수학과 파이썬 복습은 패스하겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. 신경망의 추론\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망\n",
    "- 입력을 출력으로 변환하는 단순한 함수\n",
    "- 입력층, 은닉층, 출력층으로 구성\n",
    "- 가중치를 학습시켜 원하는 형태 구성 및 이전 뉴런의 값에 영향을 받지 않는 편향 존재\n",
    "\n",
    "![](img/chap_01/1.png)\n",
    "\n",
    "- 은닉층의 첫번째 뉴런의 계산 공식\n",
    "    - ![](img/chap_01/2.png)\n",
    "\n",
    "- 실제 완전연결 계층이 수행하는 변환을 다음과 같이 행렬의 곱으로 정리 가능\n",
    "    - ![](img/chap_01/3.png)\n",
    "    - 다음과 같이 간소화 할 수 있음\n",
    "        - ![](img/chap_01/4.png)\n",
    "        \n",
    "- 샘플 데이터에 따른 데이터 형상 확인\n",
    "\n",
    "![](img/chap_01/5.png)\n",
    "![](img/chap_01/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 변환과 비선형 변환\n",
    "- 일반적인 완전연결계층에 의한 변환은 선형 변환임\n",
    "- 선형 변환만으로는 은닉층이 없는 네트워크와 다를 바가 없음\n",
    "- 비선형 활성화 함수를 이용하여 신경망의 표현력을 높일 수 있음\n",
    "\n",
    "#### Sigmoid function\n",
    "- 기본적인 활성화 함수\n",
    "- 임의의 실수를 입력받아 0 ~ 1 사이의 실수를 출력\n",
    "- 선형 회귀에서 많이 사용\n",
    "\n",
    "![](img/chap_01/7.png)\n",
    "\n",
    "![](img/chap_01/8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine 계층과 Sigmoid 계층의 순전파\n",
    "- 각 계층을 파이썬 클래스로 구현\n",
    "- 모든 계층은 forward()와 backward()메서드를 가짐\n",
    "- 모든 계층은 params와 grads를 인스턴스 변수로 가짐\n",
    "- params: 가중치 및 편향 등의 값을 담는 리스트\n",
    "- grads: params에 저장된 매개변수에 대응하는 기울기를 담는 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. 신경망의 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "- 신경망의 학습이 얼마나 잘 되고 있는가를 알기 위한 척도 필요\n",
    "- 손실을 사용하여 학습 단계의 특정 시점의 신경망의 성능을 나타냄\n",
    "- 손실은 정답 라벨과 신경망이 예측한 결과를 비교하여 예측의 차이를 나타내는 스칼라 값\n",
    "\n",
    "### Softmax\n",
    "- n개의 입력에 대해 n개의 출력을 내보내며, 각 출력은 0.0 이상 1.0 이하의 실수, 모든 출력의 합은 1.0 => 각 출력을 확률로 해석 가능\n",
    "- 출력이 총 n개일 때, k번째 출력 y_k를 구하는 계산식\n",
    "    \n",
    "    ![](img/chap_01/10.png)\n",
    "\n",
    "### Cross Entropy Error\n",
    "- 다중 클래스 분류 신경망에서 흔히 사용하는 손실 함수\n",
    "- 신경망이 출력하는 각 클래스의 확률과 정답 레이블을 이용해 구할 수 있음\n",
    "- 출력이 총 k개일 때, cross entropy error를 구하는 계산식\n",
    "\n",
    "    ![](img/chap_01/11.png)\n",
    "    - t_k는 k번째 클래스에 해당하는 정답 레이블(0 or 1)\n",
    "    - 정답 레이블은 t = [0, 0, 1]과 같이 ont-hot vector로 표기\n",
    "    - y_k는 k번째 출력의 softmax를 계산한 확률값\n",
    "    \n",
    "- 실제로 cross entropy error은 정답 레이블이 1인 원소의 출력값의 자연로그 값\n",
    "- 다른 원소들은 t_k(정답레이블)가 0이기 때문에 결과에 영향을 주지 못함\n",
    "\n",
    "#### 미니 배치를 고려한 Cross Entropy Error\n",
    "- 데이터가 N개이며, t_nk는 n번째 데이터의 k차원째의 값(0 or 1)\n",
    "- 데이터를 N개로 확장하였고, 이를 N으로 나눠 1개당 평균 손실함수를 구함\n",
    "    \n",
    "    ![](img/chap_01/12.png)\n",
    "\n",
    "![](img/chap_01/9.png)\n",
    "       \n",
    "#### 일반적으로 softmax와 cross entropy를 Softmax with Loss 계층 하나로 구현하며, 이로인해 역전파 계산이 쉬워짐\n",
    "![](img/chap_01/13.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분과 기울기\n",
    "- 벡터의 각 원소에 대한 미분을 정리한 것이 기울기\n",
    "\n",
    "    ![](img/chap_01/15.png) \n",
    "\n",
    "- 벡터와 마찬가지로 행렬에서도 기울기를 정의할 수 있음\n",
    "    - W가 m x n 행렬이라면, L = g(W) 함수의 기울기는 다음과 같음\n",
    "    - 이때, W와 $\\frac{\\partial L}{\\partial W}$의 형상이 같음\n",
    "    \n",
    "        ![](img/chap_01/14.png) \n",
    "        \n",
    "        \n",
    "### 오차역전파\n",
    "- 학습 시 신경망은 학습 데이터를 입력하면 손실을 출력\n",
    "- 각 매개변수에 대한 손실의 기울기를 구하고 싶음\n",
    "- 오차역전파를 사용하여 손쉽게 기울기를 구할 수 있음\n",
    "\n",
    "### 연쇄법칙\n",
    "- 합성함수에 대한 미분 법칙\n",
    "- 아무리 많은 함수를 연결해도, 각 함수의 국소적인 미분을 계산할 수 있다면 그 값들을 곱해서 전체의 미분을 구할 수 있음\n",
    "\n",
    "### 각 노드별 순전파 및 역전파 개념 및 그래프\n",
    "#### 덧셈 노드\n",
    "- $\\frac{\\partial z}{\\partial x}$와 $\\frac{\\partial z}{\\partial y}$ 모두 1\n",
    "- 덧셈 노드는 상류로부터 받은 값에 1을 곱하여 하류로 기울기를 전파 = 기울기를 그대로 전파\n",
    "\n",
    "![](img/chap_01/16.png) \n",
    "\n",
    "#### 곱셈 노드\n",
    "- $\\frac{\\partial z}{\\partial x} = y$, $\\frac{\\partial z}{\\partial y} = x$\n",
    "- 곱셈 노드는 순전파 시의 입력을 서로 바꾼 값을 곱함\n",
    "\n",
    "![](img/chap_01/17.png) \n",
    "\n",
    "#### 분기 노드\n",
    "- 같은 값이 복제되어 분기되었기 때문에 역전파는 상류에서 온 기울기들의 합\n",
    "\n",
    "![](img/chap_01/18.png)\n",
    "\n",
    "#### Repeat 노드\n",
    "- 분기노드를 일반화한 노드\n",
    "\n",
    "![](img/chap_01/19.png) \n",
    "\n",
    "#### Sum 노드\n",
    "- 범용 덧셈 노드로, $N \\times D$ 배열을 0축(axis=0)에 대한 합을 구함\n",
    "- Sum 노드의 역전파는 상류로부터의 기울기를 하류로 분배 => 덧셈 노드의 확장\n",
    "- Sum 노드와 Repeat 노드는 서로 반대 관계\n",
    "\n",
    "![](img/chap_01/20.png) \n",
    "\n",
    "#### MATtatMul\n",
    " ㄴ노녿노드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. 신경망으로 문제를 풀다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5. 계산 고속화는 패스하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 2. 자연어와 단어의 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 자연어 처리란\n",
    "- 우리가 사용하는 말을 컴퓨터에게 이해시키기 위한 기술\n",
    "- 컴퓨터에게 자연어를 이해시킬 수 있다면, 검색엔진, 기계번역 등과 같은 기술에 널리 사용 가능\n",
    "\n",
    "### 단어의 의미\n",
    "- 말은 문자로 구성되며, 말의 의미는 단어로 구성\n",
    "- 단어란, 의미의 최소단위이며, 컴퓨터에게 단어의 의미를 이해시키는 것은 중요\n",
    "- '시소러스', '통계 기반 기법', '추론 기반 기법' 등을 통해 단어의 의미를 표현할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 시소러스\n",
    "- 우리가 각각의 단어에 의미를 설명해 넣는 것처럼, 컴퓨터가 이해할 수 있는 형태의 사전 형식\n",
    "- 뜻이 같은 단어나 뜻이 비슷한 단어가 한 그룹으로 분류\n",
    "\n",
    "    ![](img/chap_01/21.png) \n",
    "    \n",
    "- 단어 사이의 상위-하위 혹은 전체-부분 등 의 관계까지 묘사할 수 있음\n",
    "\n",
    "    ![](img/chap_01/21.png) \n",
    "    \n",
    "- 이러한 단어 네트워크를 통해 컴퓨가 간접적으로 단어의 의미를 이해했다고 할 수 있음\n",
    "- 자연어 처리 분야에서 WordNet이라는 시소러스가 가장 유명함\n",
    "\n",
    "### 시소러스의 문제점\n",
    "- 시대 변화에 대응하기 어려움\n",
    "- 사람을 쓰는 비용이 큼\n",
    "- 단어의 미묘한 차이를 표현할 수 없음\n",
    "\n",
    "#### => 이를 해결하기 위해 통계 기반 기법과 신경망을 사용한 추론 기반 기법을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 통계 기반 기법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
